name: Fiap Cloud Games CI - User API

on:
  push:
    branches: [ 'main']
  pull_request:
    types: [opened, synchronize]

env:
  AWS_REGION: us-east-1
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  ECR_REPOSITORY: fcg-user-api
  EKS_CLUSTER: fcg
  K8S_NAMESPACE: fcg
  HELM_RELEASE_NAME: user-api

jobs:
  build:
    name: Build the solution
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Build
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: 8.0.x
      - run: |
          dotnet restore
          dotnet build --no-restore --configuration Release
          
      - name: Upload build output
        uses: actions/upload-artifact@v4
        with:
          name: Build Output
          path: |
            ./
  tests:
    name: Run unit tests
    needs: build
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
         
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: Build Output
          path: ./build_result
        
      - name: Unit Tests
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: 8.0.x
      - run: dotnet test ./build_result/FCGUserApi.sln --logger trx --results-directory "Results"

      - name: Upload test restult
        uses: actions/upload-artifact@v4
        with:
          name: Test Results
          path: "Results"
        if: ${{ always() }}

      - name: Test Report
        uses: dorny/test-reporter@v2
        if: always()
        with:
          name: .NET Tests Report
          path: "**/*.trx"
          reporter: dotnet-trx
          fail-on-error: true

  build-push:
    name: Build and Push Docker Image
    needs: [build, tests]
    # TODO: if: github.event_name == 'push'
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Generate Docker metadata
        id: meta
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          IMAGE_TAG="${{ github.sha }}"
          echo "tags=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT
          echo "latest=$ECR_REGISTRY/$ECR_REPOSITORY:latest" >> $GITHUB_OUTPUT
      
      - name: Build and Push Docker Image
        env:
          IMAGE_TAG: ${{ steps.meta.outputs.tags }}
          IMAGE_LATEST: ${{ steps.meta.outputs.latest }}
        run: |
          echo "Building Docker image..."
          docker build -t $IMAGE_TAG -t $IMAGE_LATEST .
          
          echo "Pushing to ECR..."
          docker push $IMAGE_TAG
          docker push $IMAGE_LATEST
          
          echo "Image pushed successfully"
          echo "Tag: $IMAGE_TAG"
          echo "Latest: $IMAGE_LATEST"

  deploy-eks:
    name: Deploy to EKS
    needs: [build-push, migration]
    # TODO: Descomentar antes de fazer o merge if: github.event_name == 'push'
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      # Configura kubectl para se conectar ao cluster EKS
      # Isso cria/atualiza o arquivo ~/.kube/config com as credenciais do cluster
      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER }}
          kubectl cluster-info
      
      # Instala eksctl - ferramenta CLI para gerenciar clusters EKS
      # Usado para criar IRSA (IAM Roles for Service Accounts)
      - name: Install eksctl
        run: |
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz"
          tar -xzf eksctl_Linux_amd64.tar.gz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          eksctl version
      
      # IRSA (IAM Roles for Service Accounts) permite que pods no Kubernetes
      # assumam roles IAM da AWS sem usar credenciais estáticas.
      # Isso é necessário para o External Secrets Operator acessar o AWS Secrets Manager.
      # 
      # Como funciona:
      # 1. Cria um ServiceAccount no Kubernetes (fcg-user-api-sa)
      # 2. Cria uma IAM Role vinculada ao ServiceAccount via OIDC
      # 3. Anexa a policy FCGExternalSecretsPolicy à role
      # 4. Pods que usam esse ServiceAccount podem acessar Secrets Manager
      - name: Create/Update IRSA for External Secrets
        run: |
          echo "Checking if IRSA already exists..."
          if kubectl get serviceaccount fcg-user-api-sa -n ${{ env.K8S_NAMESPACE }} &>/dev/null; then
            echo "ServiceAccount already exists, skipping IRSA creation"
            IRSA_EXISTS=true
          else
            echo "Creating IRSA for fcg-user-api-sa..."
            eksctl create iamserviceaccount \
              --cluster=${{ env.EKS_CLUSTER }} \
              --namespace=${{ env.K8S_NAMESPACE }} \
              --name=fcg-user-api-sa \
              --attach-policy-arn=arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:policy/FCGExternalSecretsPolicy \
              --approve \
              --region=${{ env.AWS_REGION }}
            
            echo "IRSA created successfully"
            echo "Waiting 30s for IAM propagation..."
            sleep 30
            IRSA_EXISTS=false
          fi
      
      # Helm é o gerenciador de pacotes do Kubernetes
      # Permite deployar aplicações usando templates (charts)
      - name: Install Helm
        run: |
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version
      
      # Deploy da aplicação no EKS usando Helm
      # O comando "upgrade --install" faz:
      # - Se o release não existe: instala (primeira vez)
      # - Se já existe: atualiza (deploys subsequentes)
      # 
      # O chart em ./k8s/ contém:
      # - Deployment: define os pods da aplicação
      # - Service: expõe os pods internamente
      # - Ingress: cria ALB para acesso externo
      # - HPA: autoscaling baseado em CPU/memória
      # - ExternalSecret: sincroniza secrets do AWS Secrets Manager
      - name: Deploy to EKS with Helm
        env:
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Deploying FCG User API to EKS..."
          
          helm upgrade --install ${{ env.HELM_RELEASE_NAME }} ./k8s \
            --namespace ${{ env.K8S_NAMESPACE }} \
            --create-namespace \
            --set image.tag=$IMAGE_TAG \
            --timeout 10m
          
          echo "Helm deployment completed"
      
      # External Secrets Operator sincroniza secrets do AWS Secrets Manager
      # para Kubernetes Secrets. Aguardamos a sincronização antes de verificar
      # os pods, pois eles dependem desses secrets (connection string, JWT config, etc)
      - name: Wait for External Secrets sync
        run: |
          echo "Waiting for External Secrets to sync..."
          
          kubectl wait --for=condition=Ready \
            externalsecret/${{ env.HELM_RELEASE_NAME }}-fcg-user-api-externalsecret \
            -n ${{ env.K8S_NAMESPACE }} \
            --timeout=120s
          
          echo "External Secrets synced successfully"
      
      # Verifica se o deployment foi concluído com sucesso
      # "kubectl rollout status" aguarda até que:
      # - Todos os pods novos estejam Running
      # - Todos os pods antigos sejam terminados
      # - Health checks (readiness/liveness) passem
      - name: Verify Deployment
        run: |
          echo "Verifying deployment rollout..."
          
          DEPLOYMENT_NAME="${{ env.HELM_RELEASE_NAME }}-fcg-user-api"
          
          kubectl rollout status deployment/$DEPLOYMENT_NAME -n ${{ env.K8S_NAMESPACE }} --timeout=10m
          
          echo ""
          echo "Deployment completed successfully"
          kubectl get pods -n ${{ env.K8S_NAMESPACE }} -l app.kubernetes.io/name=fcg-user-api
      
      # Obtém a URL do ALB (Application Load Balancer)
      # O AWS Load Balancer Controller cria automaticamente um ALB quando
      # o Ingress é criado. O ALB distribui tráfego entre os pods da aplicação.
      # 
      # Nota: O ALB pode levar 2-3 minutos para ser provisionado na primeira vez.
      # Em deploys subsequentes, o mesmo ALB é reutilizado (via annotation group.name).
      - name: Get ALB URL
        run: |
          INGRESS_NAME="${{ env.HELM_RELEASE_NAME }}-fcg-user-api"
          ALB_URL=$(kubectl get ingress -n ${{ env.K8S_NAMESPACE }} $INGRESS_NAME -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          
          if [ -z "$ALB_URL" ]; then
            echo "ALB is being provisioned. Check status:"
            echo "kubectl get ingress -n ${{ env.K8S_NAMESPACE }}"
          else
            echo ""
            echo "=========================================="
            echo "DEPLOYMENT SUCCESSFUL"
            echo "=========================================="
            echo "API URL: http://$ALB_URL"
            echo "Health Check: http://$ALB_URL/health"
            echo "=========================================="
          fi

  migration:
    name: Deploy DB (migrations)
    needs: [build, tests]
    environment: production
    runs-on: 
      - self-hosted
      - linux
      - X64
    env:
      RDS_CONNECTION_STRING: ''
  
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}


      - name: Get RDS connection string from Secrets Manager
        id: get-rds-secret
        run: |
          SECRET_JSON=$(aws secretsmanager get-secret-value \
            --secret-id fcg-api-user-connection-string \
            --query SecretString \
            --output text)
          echo "RDS_CONNECTION_STRING=$SECRET_JSON" >> $GITHUB_ENV
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          
      - name: Add global tools to PATH
        run: echo "$HOME/.dotnet/tools" >> $GITHUB_PATH

      - name: Apply migrations
        env:
          ConnectionStrings__DefaultConnection: ${{ env.RDS_CONNECTION_STRING }}
        run: |
          dotnet ef database update \
            --configuration Release \
            --project src/Adapters/Drivers/FCGUser.Api/FCGUser.Api.csproj \
            --connection "$ConnectionStrings__DefaultConnection"